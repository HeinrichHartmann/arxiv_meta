["1104.0729",{"format":[],"subject":["Computer Science - Learning","Statistics - Machine Learning"],"relation":[],"rights":[],"publisher":[],"source":[],"contributor":[],"identifier":["http://arxiv.org/abs/1104.0729","27th Conference on Uncertainty in Artificial Intelligence (UAI\n  2011)"],"date":["2011-04-05","2011-06-16"],"type":["text"],"creator":["Rostamizadeh, Afshin","Agarwal, Alekh","Bartlett, Peter"],"language":[],"coverage":[],"title":["Online and Batch Learning Algorithms for Data with Missing Features"],"description":["  We introduce new online and batch algorithms that are robust to data with\nmissing features, a situation that arises in many practical applications. In\nthe online setup, we allow for the comparison hypothesis to change as a\nfunction of the subset of features that is observed on any given round,\nextending the standard setting where the comparison hypothesis is fixed\nthroughout. In the batch setup, we present a convex relation of a non-convex\nproblem to jointly estimate an imputation function, used to fill in the values\nof missing features, along with the classification hypothesis. We prove regret\nbounds in the online setting and Rademacher complexity bounds for the batch\ni.i.d. setting. The algorithms are tested on several UCI datasets, showing\nsuperior performance over baselines.\n"]}]
["1105.1178",{"format":[],"subject":["Computer Science - Learning","Computer Science - Data Structures and Algorithms","Statistics - Machine Learning"],"relation":[],"rights":[],"publisher":[],"source":[],"contributor":[],"identifier":["http://arxiv.org/abs/1105.1178"],"date":["2011-05-05"],"type":["text"],"creator":["Tarlow, Daniel","Givoni, Inmar E.","Zemel, Richard S.","Frey, Brendan J."],"language":[],"coverage":[],"title":["Interpreting Graph Cuts as a Max-Product Algorithm"],"description":["  The maximum a posteriori (MAP) configuration of binary variable models with\nsubmodular graph-structured energy functions can be found efficiently and\nexactly by graph cuts. Max-product belief propagation (MP) has been shown to be\nsuboptimal on this class of energy functions by a canonical counterexample\nwhere MP converges to a suboptimal fixed point (Kulesza & Pereira, 2008).\n  In this work, we show that under a particular scheduling and damping scheme,\nMP is equivalent to graph cuts, and thus optimal. We explain the apparent\ncontradiction by showing that with proper scheduling and damping, MP always\nconverges to an optimal fixed point. Thus, the canonical counterexample only\nshows the suboptimality of MP with a particular suboptimal choice of schedule\nand damping. With proper choices, MP is optimal.\n"]}]
["1108.5710",{"format":[],"subject":["Computer Science - Computer Vision and Pattern Recognition","Computer Science - Artificial Intelligence"],"relation":[],"rights":[],"publisher":[],"source":[],"contributor":[],"identifier":["http://arxiv.org/abs/1108.5710"],"date":["2011-08-29"],"type":["text"],"creator":["Schmidt, Mark","Alahari, Karteek"],"language":[],"coverage":[],"title":["Generalized Fast Approximate Energy Minimization via Graph Cuts:\n  Alpha-Expansion Beta-Shrink Moves"],"description":["  We present alpha-expansion beta-shrink moves, a simple generalization of the\nwidely-used alpha-beta swap and alpha-expansion algorithms for approximate\nenergy minimization. We show that in a certain sense, these moves dominate both\nalpha-beta-swap and alpha-expansion moves, but unlike previous generalizations\nthe new moves require no additional assumptions and are still solvable in\npolynomial-time. We show promising experimental results with the new moves,\nwhich we believe could be used in any context where alpha-expansions are\ncurrently employed.\n","Comment: Conference on Uncertainty in Artificial Intelligence (2011)"]}]
